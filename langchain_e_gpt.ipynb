{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "# Desenvolvimento RAG\n",
        "\n",
        "Anotações feitas pelo prof:\n",
        "\n",
        "**Toda a execução ocorre no Google Colaboratory.**\n",
        "\n",
        "Pré-requisitos:\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "- Configurar o notebook para usar GPU- Acesse o menu 'Ambiente de Execução -> Alterar o tipo do ambiente de execução -> Acelerador de hardware -> T4 GPU\n",
        "\n",
        "\n",
        "**Referências**\n",
        "\n",
        "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed\n",
        "\n",
        "**Lista dos modelos:**\n",
        "\n",
        "https://huggingface.co/models\n",
        "\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "# Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_O5mNHKt2oW"
      },
      "source": [
        "### Data e hora de execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpNBAbS1t5Xu",
        "outputId": "f6b5dfc1-9df1-465f-f89d-9784311958bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/03/2024 14:50:09\n"
          ]
        }
      ],
      "source": [
        "# Biblioteca de date\n",
        "from datetime import datetime\n",
        "\n",
        "data_e_hora_atuais = datetime.now()\n",
        "data_e_hora_em_texto = data_e_hora_atuais.strftime('%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "print(data_e_hora_em_texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "### Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "outputs": [],
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-xSroBtxPL2"
      },
      "source": [
        "## Versão Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xu2haQbxRTc",
        "outputId": "32ae4b95-246c-4a33-9706-13c8d8a12c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versão Python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]\n"
          ]
        }
      ],
      "source": [
        "# Biblioteca do sistema\n",
        "import sys\n",
        "\n",
        "print(\"Versão Python:\", sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKmhxcvIfbG2"
      },
      "source": [
        "## Funções auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603LYIYKBmq5"
      },
      "source": [
        "Função auxiliar para formatar o tempo como `hh: mm: ss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "Guy6B4whsZFR"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas.\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def formataTempo(tempo):\n",
        "    \"\"\"\n",
        "      Pega a tempo em segundos e retorna uma string hh:mm:ss\n",
        "    \"\"\"\n",
        "    # Arredonda para o segundo mais próximo.\n",
        "    tempo_arredondado = int(round((tempo)))\n",
        "\n",
        "    # Formata como hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=tempo_arredondado))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1vu-ch8yT5R"
      },
      "source": [
        "Imprime linhas menores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "8BKQZtF9yUBs"
      },
      "outputs": [],
      "source": [
        "def print_linhas_menores(texto, tamanho=120):\n",
        "  for i in range(0, len(texto), tamanho):\n",
        "    print(texto[i:i+tamanho])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "# 1 - Instalação das bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akFHj1OT0eCc"
      },
      "source": [
        "Biblioteca para manipular pdf\n",
        "\n",
        "https://pypi.org/project/pypdf/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHKbYosXal6M"
      },
      "source": [
        "Bibliota de dependência para manipular os embeddings pelo Langchain.\n",
        "\n",
        "https://pypi.org/project/sentence-transformers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX6UfQIXbZGt"
      },
      "source": [
        "Biblioteca que persiste os embeddings e realiza busca semântica.\n",
        "\n",
        "https://pypi.org/project/chromadb/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGrlTKgSLdNj"
      },
      "source": [
        "Bibioteca LangChain é um framework de código aberto para o desenvolvimento de aplicações usando modelos de linguagem grandes.\n",
        "\n",
        "https://pypi.org/project/langchain/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upho_jty-L2R"
      },
      "source": [
        "Dependências do xformers\n",
        "\n",
        "https://pypi.org/project/lmdb/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDqzuP1kqPZh"
      },
      "source": [
        "Permite maior velocidade e menor consumo de memória nos transformers.\n",
        "\n",
        "https://pypi.org/project/xformers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp0jVfo3QM3h"
      },
      "source": [
        "O bitsandbytes é um wrapper leve em torno de funções personalizadas CUDA, em particular otimizadores de 8 bits, multiplicação de matrizes (LLM.int8()) e funções de quantização. É uma dependência do accelerate.\n",
        "\n",
        "https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
        "\n",
        "https://pypi.org/project/bitsandbytes/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wU6vuyAuPd"
      },
      "source": [
        "Accelerate é uma biblioteca que permite que o mesmo código PyTorch seja executado em qualquer configuração distribuída adicionando apenas quatro linhas de código. Otimiza as operações do PyTorch, especialmente na GPU.\n",
        "\n",
        "https://pypi.org/project/accelerate/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "A Biblioteca A Biblioteca Transformers fornece APIs e ferramentas para baixar e treinar facilmente modelos pré-treinados de última geração para Processamento de linguagem natural, Visão computacional, Áudio, etc.\n",
        "\n",
        "Fornece uma maneira direta de usar modelos pré-treinados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlrWrRP02tuZ"
      },
      "source": [
        "A Biblioteca huggingface-cli fornece vários comandos para interagir com o Hugging Face Hub a partir da linha de comando. Um desses comandos é o login, que permite aos usuários se autenticarem no Hub usando suas credenciais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NdUAv1OyE7v"
      },
      "source": [
        "## Versão bibliotecas instaladas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w7ApoLkx83r"
      },
      "source": [
        "## Carrega os documentos de PDF\n",
        "\n",
        "https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "4lWAxx_Wv3YY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:/Users/miyun/Downloads/edital3_val.pdf\n"
          ]
        }
      ],
      "source": [
        "from tkinter import *\n",
        "from tkinter import filedialog\n",
        "\n",
        "def escolher_pdf():\n",
        "    arquivo_pdf = filedialog.askopenfilename(title=\"Escolha o arquivo PDF\")\n",
        "    print(arquivo_pdf)\n",
        "    return arquivo_pdf\n",
        "pdf_escolhido = escolher_pdf()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRx-vabm0Vbc"
      },
      "source": [
        "#### Carrega o PDF\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "j18ncV8e0B8M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:/Users/miyun/Downloads/edital3_val.pdf\n",
            "Documentos carregados: 17\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "\n",
        "\n",
        "# Define o diretório\n",
        "pdf = pdf_escolhido\n",
        "print(pdf)\n",
        "# Pode ser usado o PyPDFDirectoryLoader para um diretorio\n",
        "carregador = PyPDFLoader(pdf)\n",
        "\n",
        "# Carrega os documentos\n",
        "documentos = carregador.load()\n",
        "\n",
        "print(f\"Documentos carregados: {len(documentos)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE12a2SGoFCG"
      },
      "source": [
        "Exibe parte dos dados carregados do PDF ou HTML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "hQFU9kiPVT5B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantidade de documentos(páginas): 17\n",
            "Trecho página( 2 ) :  \n",
            " \n",
            " 3 de 17 \n",
            "ferramentas de análise como Avaliação do Ciclo de Vida (ACV), Avaliação do Ciclo de \n",
            "Vida Social (ACVS) e a Economia Circular (EC). \n",
            "c.4 Pesquisa e desenvolvimento de tecnologias e processos para reuso e reciclagem \n",
            "de resíduos da produção de rochas ornamentais, agregados para construção civil, \n",
            "gesso, gemas e joias, cerâmica vermelha e cerâmica de revestimento, incluindo \n",
            "ferramentas de análise como Avaliação do Ciclo de Vida (ACV), Avaliação do Ciclo de \n",
            "Vida Social (ACVS) e a Ec\n",
            "\n",
            "Metadados: {'source': 'C:/Users/miyun/Downloads/edital3_val.pdf', 'page': 0}\n"
          ]
        }
      ],
      "source": [
        "print(\"Quantidade de documentos(páginas):\", len(documentos))\n",
        "pagina = 2\n",
        "print(\"Trecho página(\", pagina, \") :\", documentos[pagina].page_content[0:500])\n",
        "print()\n",
        "print(\"Metadados:\", documentos[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikuv-cM5xFCb"
      },
      "source": [
        "# 3 - Manda para a requisição GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "7xthrVA3xLDT"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "prompt_sys_info_relevantes = \"\"\"\n",
        "    Você é um assistente que resume as informações mais relevantes para a inscrição de um edital. Você recebe como entrada o conteúdo do PDF do edital em questão e na saída você devolve as informações resumidas. Sua resposta deve ter no máximo 600 caractéres.\n",
        "    Caso o trecho do PDF não tenha informações relevantes para inscrição, retorne \"NULL\".\n",
        "\n",
        "    ##### EXEMPLO DE ENTRADA\n",
        "    [conteúdo pdf do edital]\n",
        "\n",
        "    ##### EXEMPLO DE SAÍDA\n",
        "    [nome do edital],\n",
        "    [datas de subimissão],\n",
        "    [datas de fechamento de inscrição],\n",
        "    [pré requisitos para inscrição],\n",
        "    [maturidade da startup para submissão],\n",
        "    [tipo de financiamento],\n",
        "    ...\n",
        "\n",
        "    \"\"\"\n",
        "prompt_sys_titulo = \"\"\" \n",
        "Você lê as duas primeiras páginas de um edital e extrai o título dele. Caso não encontre um título, crie um coerente ao conteúdo exposto. Retire todos os acentos e caractéres especiais do título. O título deve ter no máximo 60 caracteres.\n",
        "    ##### EXEMPLO DE ENTRADA\n",
        "    [conteúdo das 2 primeiras páginas do pdf do edital]\n",
        "\n",
        "    ##### EXEMPLO DE SAÍDA\n",
        "    [título sem acentos ou caracteres especiais]\n",
        "\"\"\"\n",
        "max_tokens = 400\n",
        "\n",
        "key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def chamada_gpt(prompt_user, prompt_sys):\n",
        "    client = OpenAI(api_key=key)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"system\", \"content\": prompt_sys},\n",
        "                  {\"role\": \"user\", \"content\": prompt_user}],\n",
        "        temperature=1,\n",
        "        max_tokens=max_tokens,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "        )\n",
        "\n",
        "    print(response.choices[0].message.content)\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "B-5szFjs57Uy"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "def calcula_token(prompt, prompt_sys):\n",
        "    dolar = 4.97\n",
        "    modelo = \"gpt-3.5-turbo\"\n",
        "\n",
        "    dict_modelo = {\"gpt-4-0125-preview\": 0.01, \"gpt-4\": 0.03, \"gpt-4-32k\": 0.06, \"gpt-3.5-turbo-0125\": 0.0005, \"gpt-3.5-turbo-instruct\": 0.0015, \"gpt-3.5-turbo\": 0.0015}\n",
        "\n",
        "\n",
        "    codificador = tiktoken.encoding_for_model(modelo)\n",
        "    lista_tokens_entrada = codificador.encode(prompt+prompt_sys)\n",
        "\n",
        "    nro_tokens_entrada = len(lista_tokens_entrada)\n",
        "    nro_tokens_saida = max_tokens\n",
        "    nro_tokens_total = nro_tokens_saida + nro_tokens_entrada\n",
        "    valor = dict_modelo[modelo]\n",
        "    custo = float(nro_tokens_total/1000 * valor)\n",
        "\n",
        "    print(f\"Com um prompt de {nro_tokens_total} tokens o custo será de {custo} dolares ou {custo*dolar} reais\")\n",
        "\n",
        "    return custo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "wkhuhtyvzhoN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Com um prompt de 1305 tokens o custo será de 0.0019575 dolares ou 0.009728775 reais\n",
            "Com um prompt de 1443 tokens o custo será de 0.0021645 dolares ou 0.010757565 reais\n",
            "Com um prompt de 1353 tokens o custo será de 0.0020295 dolares ou 0.010086615 reais\n",
            "Com um prompt de 1356 tokens o custo será de 0.0020340000000000002 dolares ou 0.01010898 reais\n",
            "Com um prompt de 1453 tokens o custo será de 0.0021795 dolares ou 0.010832115 reais\n",
            "Com um prompt de 1450 tokens o custo será de 0.002175 dolares ou 0.010809749999999998 reais\n",
            "Com um prompt de 1354 tokens o custo será de 0.0020310000000000003 dolares ou 0.01009407 reais\n",
            "Com um prompt de 1263 tokens o custo será de 0.0018945 dolares ou 0.009415664999999998 reais\n",
            "Com um prompt de 1260 tokens o custo será de 0.00189 dolares ou 0.009393299999999999 reais\n",
            "Com um prompt de 1205 tokens o custo será de 0.0018075 dolares ou 0.008983275 reais\n",
            "Com um prompt de 2105 tokens o custo será de 0.0031575 dolares ou 0.015692775 reais\n",
            "0.0233205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:18,622 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELEÇÃO PÚBLICA MCTI/FINEP/FNDCT - Subvenção Econômica à Inovação – 10/2022, \n",
            "Datas de submissão: Não especificadas, \n",
            "Datas de fechamento de inscrição: Não especificadas, \n",
            "Pré-requisitos para inscrição: Desenvolver produtos, processos e/ou serviços inovadores relacionados às linhas temáticas, \n",
            "Maturidade da startup para submissão: Projetos de risco tecnológico de níveis de maturidade tecnológica (TRLs) 4 a 7, \n",
            "Tipo de financiamento: Recursos de subvenção econômica.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:19,888 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NULL.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:20,787 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NULL.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:21,492 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NULL\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:22,345 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NULL\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:25,885 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RESULTADOS, DELIBERAÇÃO E INTERPOSIÇÃO DE RECURSOS  \n",
            "- Serão divulgados resultados preliminares da 1ª e 2ª etapas, com prazo para interposição de recursos. Recursos devem obedecer requisitos específicos e apenas um recurso por proposta é aceito. \n",
            "CONTRATAÇÃO E REPASSE DE RECURSOS SUBVENCIONADOS  \n",
            "- Propostas aprovadas devem ser contratadas em até 90 dias após divulgação do resultado final, podendo haver prorrogação. Visitas técnicas podem ser realizadas para verificação dos dados informados na proposta.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:26,780 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NULL\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:27,709 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "NULL\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:30,838 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seleção Pública Finep\n",
            "Datas: \n",
            "- Recurso: 03/11/2022\n",
            "- Resultado Final: 14/11/2022\n",
            "Pré-requisitos: Conformidade com itens do edital e legislação vigente. Compromisso com veracidade das informações.\n",
            "Maturidade da startup: Nível de maturidade tecnológica definido em anexo.\n",
            "Outras informações: Acompanhamento técnico e financeiro pela Finep. Proteção da propriedade intelectual obrigatória. Possibilidade de revogação ou anulação do processo seletivo.\n",
            "NULL\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:33,701 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seleção Pública Finep:\n",
            "- Não há datas de submissão ou fechamento de inscrição mencionadas.\n",
            "- Pré requisitos: Consentimento dos titulares dos dados pessoais e documentos específicos.\n",
            "- Maturidade da startup: Não especificada.\n",
            "- Tipo de financiamento: Subvenção econômica.\n",
            "- Contato para dúvidas: sac@finep.gov.br.\n",
            "- Penalidades para descumprimento das normas e legislação vigente.\n",
            "- Omissões serão decididas pelo Diretor da Diretoria de Inovação.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:35,248 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECAO PUBLICA MCTI FINEP FNDCT Subvencao Economica a Inovacao 10/2022 Programa Mineracao e Desenvolvimento\n"
          ]
        }
      ],
      "source": [
        "informacoes_relevantes = []\n",
        "\n",
        "#Calculo de tokens\n",
        "conteudo = []\n",
        "quota_max = 0.1\n",
        "quota = 0\n",
        "titulo = \"Não informado\"\n",
        "\n",
        "for pagina in documentos[:5]:\n",
        "  quota += calcula_token(pagina.page_content, prompt_sys_info_relevantes)\n",
        "for pagina in documentos[-5:]:\n",
        "  quota += calcula_token(pagina.page_content, prompt_sys_info_relevantes)\n",
        "quota += calcula_token(documentos[0].page_content + documentos[1].page_content, prompt_sys_titulo)\n",
        "print(quota)\n",
        "\n",
        "if quota < quota_max :\n",
        "  for pagina in documentos[:5]:\n",
        "    informacoes_relevantes.append(chamada_gpt(pagina.page_content, prompt_sys_info_relevantes))\n",
        "  for pagina in documentos[-5:]:\n",
        "    informacoes_relevantes.append(chamada_gpt(pagina.page_content, prompt_sys_info_relevantes))\n",
        "  titulo = chamada_gpt(documentos[0].page_content + documentos[1].page_content, prompt_sys_titulo)\n",
        "\n",
        "else:\n",
        "  print(\"numero maximo de tokens ultrapassado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "Ase5zLfRUQQ4"
      },
      "outputs": [],
      "source": [
        "prompt_verifica = \"\"\"\n",
        "Você é um sistema que classifica a maturidade a qual uma startup precisa apresentar para a subimissão do edital. Como entrada você recebe informações relevantes do edital. Na saída é apenas UMA das MATURIDADES POSSÍVEIS\n",
        "\n",
        "#### MATURIDADES POSSÍVEIS\n",
        "Ideacao: Empreendedor potencial trabalhando em uma ideia de negócio. É o estágio inicial.\n",
        "Validacao: Uma startup iterando em direção ao encaixe entre Problema e Solução, validando MVPs enquanto busca clientes pagantes.\n",
        "Operacao: Empresa com um portfólio estável de clientes pagantes, consistentemente melhorando sua operação em direção à previsibilidade de receita e o encaixe entre Produto e Mercado.\n",
        "\n",
        "### EXEMPLO DE ENTRADA\n",
        "[informações relevantes do edital]\n",
        "\n",
        "### EXEMPLO DE SAÍDA\n",
        "Ideacao\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "of4Vd6RzTM30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:36,598 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operacao\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:38,370 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Por favor, forneça informações relevantes do edital para que eu possa determinar a maturidade necessária para a submissão.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:40,070 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desculpe, mas preciso de mais informações para poder fazer a classificação de maturidade da startup. Por favor, forneça mais detalhes sobre o estágio atual da empresa ou do empreendimento.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:40,909 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operacao\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:41,739 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validacao\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-18 14:50:42,571 : INFO : HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ideacao\n"
          ]
        }
      ],
      "source": [
        "respostas = []\n",
        "for i in informacoes_relevantes:\n",
        "  if i != \"NULL\":\n",
        "    respostas.append(chamada_gpt(i, prompt_verifica))\n",
        "  else:\n",
        "    informacoes_relevantes.remove(\"NULL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "kmz17dR4cNMb"
      },
      "outputs": [],
      "source": [
        "respostas_validas = []\n",
        "for j in respostas:\n",
        "  if j == \"Operacao\" or j == \"Ideacao\" or j == \"Validacao\":\n",
        "    respostas_validas.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "9DiOEBlqWhTo"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def termo_mais_frequente(lista_strings):\n",
        "    # Concatenando todas as strings em uma única string\n",
        "    todas_as_palavras = ' '.join(lista_strings)\n",
        "    # Dividindo a string em palavras individuais\n",
        "    palavras = todas_as_palavras.split()\n",
        "    # Contando a ocorrência de cada palavra\n",
        "    contagem = Counter(palavras)\n",
        "    # Encontrando o termo mais frequente\n",
        "    termo_mais_frequente, frequencia = contagem.most_common(1)[0]\n",
        "\n",
        "    return termo_mais_frequente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "gggChaAuWlGD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECAO PUBLICA MCTI FINEP FNDCT Subvencao Economica a Inovacao 10/2022 Programa Mineracao e Desenvolvimento Operacao\n"
          ]
        }
      ],
      "source": [
        "etapa = termo_mais_frequente(respostas_validas)\n",
        "print(titulo, etapa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "# Abrir o arquivo CSV em modo de escrita e crie um escritor CSV\n",
        "with open(\"resultados.csv\", mode='a', newline='') as arquivo_csv:\n",
        "    escritor_csv = csv.writer(arquivo_csv)\n",
        "    # Escreva os dados nas linhas do CSV\n",
        "    escritor_csv.writerow([titulo, etapa])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xyxb5Px3p1-e",
        "Pqa-7WXBAw8q",
        "9NdUAv1OyE7v"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
